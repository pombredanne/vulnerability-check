import requests
import sqlite3
import xml.etree.ElementTree as ET
from datetime import datetime


def process_alas_data(url, db_file):
    """
    Retrieve XML data from the specified URL and process it,
    storing the extracted data into a SQLite database.

    Args:
        url (str): The URL of the RSS feed.
        db_file (str): The filename of the SQLite database.

    Returns:
        int: The number of new items inserted into the database.
    """

    # Retrieve XML data from the URL
    response = requests.get(url)
    xml_data = response.content
    
    # Parse the XML data
    root = ET.fromstring(xml_data)
    print(len(root.findall('channel/item')))
    # Create a connection to the SQLite database
    conn = sqlite3.connect(db_file)
    cursor = conn.cursor()

    # Create a table to store the items if it doesn't exist
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS alas_data (
            alas_id TEXT,
            severity TEXT,
            description TEXT,
            package_name TEXT,
            cve TEXT,
            released_on TEXT,
            last_build_date TEXT,
            resource_url TEXT
        )
    ''')
    conn.commit()
    # Track the number of new items inserted
    new_items_count = 0

    # Process each item in the XML
    for item in root.findall('channel/item'):
        title = item.find('title').text
        
        cve = item.find('description').text.strip()
        released_on = datetime.strptime(item.find('pubDate').text, '%a, %d %b %Y %H:%M:%S %Z')
        released_on = released_on.strftime('%Y-%m-%dT%H:%M:%SZ')
        last_build_date = datetime.strptime(item.find('lastBuildDate').text, '%a, %d %b %Y %H:%M:%S %Z')
        last_build_date = last_build_date.strftime('%Y-%m-%dT%H:%M:%SZ')
        resource_url = item.find('link').text

        # Extract ALAS ID, severity, and package name from the title
        alas_id, severity, package_name = parse_title(title)

        # Check if the item already exists in the database based on the ALAS ID
        cursor.execute('SELECT COUNT(*) FROM alas_data WHERE alas_id = ?', (alas_id,))
        result = cursor.fetchone()
        item_exists = result[0] > 0

        if not item_exists:
            print(alas_id, severity, package_name)
            try:
                # Insert the item into the database
                cursor.execute('''
                    INSERT INTO alas_data (alas_id, severity, package_name, cve, released_on, last_build_date, resource_url)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (alas_id, severity, package_name, cve, released_on, last_build_date, resource_url))

                new_items_count += 1
            except Exception as err:
                print(err)

    # Commit the changes and close the database connection
    conn.commit()
    conn.close()

    return new_items_count


def parse_title(title):
    """
    Parse the title to extract the ALAS ID, severity, and package name.

    Args:
        title (str): The title string.

    Returns:
        tuple: The ALAS ID, severity, and package name.
    """
    # Split the title into components
    parts = title.split(' (')
    
    # Extract the ALAS ID
    alas_id = parts[0].strip()
    
    # Extract the severity
    severity = parts[1].split('):')[0].strip()
    
    # Extract the package name
    package_name = parts[1].split('): ')[1].strip()
    
    return alas_id, severity, package_name


url = 'https://alas.aws.amazon.com/AL2023/alas.rss'
db_file = 'cve_data.db'

new_items_count = process_alas_data(url, db_file)
print(f'{new_items_count} new items inserted into the database.')
